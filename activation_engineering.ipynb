{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP3ck2IcBmClb4UTekMl7Ul",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a018e585c2254aea853d4856ad0f7932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ba7b36819f34575920dab685d6634f2",
              "IPY_MODEL_01e8c91a9f744ac894aaf468cce77c40",
              "IPY_MODEL_1cba08223c4242f990e807a180c3336f"
            ],
            "layout": "IPY_MODEL_344dd9113843445a9eb3bbe9a08bf472"
          }
        },
        "7ba7b36819f34575920dab685d6634f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_095c1272cd3e47989916beb713532841",
            "placeholder": "​",
            "style": "IPY_MODEL_4066625d5dac41fdbb1bd238a33d6ded",
            "value": "Loading checkpoint shards:  33%"
          }
        },
        "01e8c91a9f744ac894aaf468cce77c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e561b4dbda934468a50eb0fd0308295e",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47c5358760b14f43a68e00f8543ba422",
            "value": 1
          }
        },
        "1cba08223c4242f990e807a180c3336f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3c4dca9353846b4a0b522fcf99bd11e",
            "placeholder": "​",
            "style": "IPY_MODEL_e127d5e7f4c24b7ab497fadafb234194",
            "value": " 1/3 [00:20&lt;00:40, 20.34s/it]"
          }
        },
        "344dd9113843445a9eb3bbe9a08bf472": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "095c1272cd3e47989916beb713532841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4066625d5dac41fdbb1bd238a33d6ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e561b4dbda934468a50eb0fd0308295e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47c5358760b14f43a68e00f8543ba422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3c4dca9353846b4a0b522fcf99bd11e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e127d5e7f4c24b7ab497fadafb234194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ciertou/with-linux/blob/main/activation_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CD-UT_-iZ-Jh",
        "outputId": "0bd1a419-747b-4754-8036-9b8c40a07aac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i love you so much!\n"
          ]
        }
      ],
      "source": [
        "print(\"i love you so much!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, output_hidden_states=True)\n",
        "#model.to(\"cpu\")\n",
        "model.eval()\n",
        "\n",
        "# Choose the layer to extract activations from\n",
        "target_layer = 6  # Adjust based on model architecture\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193,
          "referenced_widgets": [
            "a018e585c2254aea853d4856ad0f7932",
            "7ba7b36819f34575920dab685d6634f2",
            "01e8c91a9f744ac894aaf468cce77c40",
            "1cba08223c4242f990e807a180c3336f",
            "344dd9113843445a9eb3bbe9a08bf472",
            "095c1272cd3e47989916beb713532841",
            "4066625d5dac41fdbb1bd238a33d6ded",
            "e561b4dbda934468a50eb0fd0308295e",
            "47c5358760b14f43a68e00f8543ba422",
            "f3c4dca9353846b4a0b522fcf99bd11e",
            "e127d5e7f4c24b7ab497fadafb234194"
          ]
        },
        "id": "nY2jT0E0aJN3",
        "outputId": "fd7ae903-1ae6-445d-9166-88c46d094afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a018e585c2254aea853d4856ad0f7932"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the layer to extract activations from\n",
        "target_layer = 6  # Adjust based on model architecture\n",
        "\n",
        "# Sample prompts\n",
        "enthusiastic_prompts = [\n",
        "    \"I'm so excited about the new product launch!\",\n",
        "    \"What a fantastic day we're having!\",\n",
        "    \"I can't wait to try this amazing new feature!\"\n",
        "]\n",
        "\n",
        "unenthusiastic_prompts = [\n",
        "    \"The new product launch happened.\",\n",
        "    \"It's just another day.\",\n",
        "    \"There's a new feature, I guess.\"\n",
        "]\n",
        "\n",
        "def get_hidden_representation(prompt, model, tokenizer, target_layer):\n",
        "    inputs = tokenizer(prompt, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        hidden_states = outputs.hidden_states  # Tuple: (layer0, layer1, ..., layerN)\n",
        "    # Use the hidden state from the target layer for the last token\n",
        "    return hidden_states[target_layer][0, -1]  # Shape: (hidden_size,)\n",
        "\n",
        "def average_representation(prompts, model, tokenizer, target_layer):\n",
        "    vecs = [get_hidden_representation(p, model, tokenizer, target_layer) for p in prompts]\n",
        "    return torch.stack(vecs).mean(dim=0)"
      ],
      "metadata": {
        "id": "BcKhaq2laTpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Get average vectors\n",
        "E = average_representation(enthusiastic_prompts, model, tokenizer, target_layer)\n",
        "UE = average_representation(unenthusiastic_prompts, model, tokenizer, target_layer)\n",
        "\n",
        "# Step 2: Compute steering vector\n",
        "#Apply alpha to scale the steering vector\n",
        "alpha = 0.5  # <-- Adjust this value to control influence\n",
        "steering_vector = alpha * (E - UE)"
      ],
      "metadata": {
        "id": "EVb3vMs4aZSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"printing {UE}\")\n",
        "print(f\"printing {E}\")"
      ],
      "metadata": {
        "id": "LlsnoPySabUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Step 3: Modify inference with steering\n",
        "def generate_with_steering(prompt, model, tokenizer, steering_vector, target_layer, max_new_tokens=20):\n",
        "    inputs = tokenizer(prompt, return_tensors='pt')\n",
        "    input_ids = inputs['input_ids']\n",
        "    generated = input_ids.clone()\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=generated, output_hidden_states=True)\n",
        "            hidden_states = list(outputs.hidden_states)\n",
        "            # Apply the steering vector at the target layer, last token only\n",
        "            hidden_states[target_layer][0, -1] += steering_vector\n",
        "\n",
        "            # Reconstruct logits from the modified hidden state\n",
        "            next_token_logits = model.lm_head(hidden_states[-1][:, -1, :])  # (1, vocab_size)\n",
        "\n",
        "            next_token = torch.argmax(next_token_logits, dim=-1).unsqueeze(0)\n",
        "            generated = torch.cat((generated, next_token), dim=1)\n",
        "\n",
        "    return tokenizer.decode(generated[0])\n"
      ],
      "metadata": {
        "id": "ypbzTTX0adIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test it\n",
        "prompt = \"Today we are launching our new product\"\n",
        "output = generate_with_steering(prompt, model, tokenizer, steering_vector, target_layer)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "X6IkwUACagB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h0kL6gg5aje4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}